# 机器学习与算法

## 第一章

### 基本术语
术语|含义
:--:|:--:
记录|一对括号内的数据：(性别=男；年龄=12)
数据集|一组记录
示例/样本/特征向量|记录中的描述
样例|拥有标记的示例
标记|分类的结果
标记空间/输出空间|所有标记的集合
属性/特征|性别、年龄（描述事物或者对象在某方面的表现或者性质的事项）
属性值|属性的取值
属性空间/样本空间/输入空间|属性的集合
学习/训练|从数据中学得模型的过程
训练数据|训练过程中使用的数据
**训练集**|训练样本组成的集合
假设|学习的结果（找到的潜在规律），学习的目的就是为了找到最好的假设
真实/真相|规律本身
学习器|采用的模型
测试|使用学习器预测的过程
**测试样本/测试集**|被预测的样本
泛化能力|学习的模型适用于新样本的能力（评估标准）
**验证集**|使用最终训练好的模型进行预测的样本

### 分类

1. 学习方法不同：监督学习、非监督学习 
监督学习：有标记的样本，如房价预测（回归问题）、癌症的诊断（分类）
* 算法：线性回归，对数几率，决策树、支持向量机、贝叶斯、神经网络
非监督学习：无标记样本，如新闻分组（分类）
* 聚类算法、概率图模型、降维与度量学习等（原型（K均值等）、密度、层次）
半监督学习
> 给出算法能够判断算法属于哪一个类型
> 分类依据（具体）：监督学习通过有标记的数据对其进行分类或者预测，而非监督学习是直接对数据进行建模，没有给定事先标记过的训练集，也不知道输入数据对应的输出结果是什么。

## 第二章（线性回归）

**评价泛化能力**：错误率和精度的计算

误差：实际输出和真实值的差异
泛化误差：在新样本的误差
经验误差/训练误差：训练集的误差

### 过拟合
解决方案：
1. 减少特征的数量（增加特征不一定能够提高，且测试集的正确率不一定会提高）
2. 添加正则化，所有的特征都需要加入正则项。
> 注意：加入了正则化以后不一定能提高泛化性能，当正则化参数过大的时候会出现欠拟合，过小没影响。

### 模型的选择

评估的方法

**交叉验证法(k折交叉验证）**：注重在新样本上的泛化性能
* 划分子集，分层采样（尽可能保持数据分布一致性）
* 最终的结果是k次的测试结果的平均值

性能度量
**错误率和精度**
* 错误率：E = a / M
* 精度：1 - E

**查全率和查准率**
混淆矩阵：
真实情况\预测结果|正例|反例
:--:|:--:|:--:
正例|TP|FN
反例|FP|TN

解释含义，列一下公式
* 查准率（精确率）P：强调准确率，预测真实的样本中的实际真实结果的比率。
* 查全率（召回率）R：强调覆盖率，最终预测正确的结果占真实正确结果的比率，比如查找犯罪嫌疑人。

两者相互对立：PR图，BEP

度量回归任务的性能：**均方误差**
$1/m \sum_{i=1}^m (f(x_i) - y_i)^2$

**F1**
$F1=\frac{2PR}^{P+R}$

**偏差和反差**
对于回归和分类
* 偏差：度量了预测结果和真实结果的偏离程度，偏差反映了性能，刻画了学习算法的拟合能力。例如：boosting关注的是偏差，不断纠正之前模型的错误
$bias^2=(\hat{f}(x)-y)^2$
形容数据跟我们期望的中心差的有多远，算是有监督额

* 方差：度量了同样大小的训练集的变动导致算法性能的变化，刻画了数据扰动带来的影响。例如：bagging：自助采样生成了多个训练集，更加关注了方差。
$var(x)=E(f(x;D)-\hat{f}(x))$
形容数据分散程度的，算是无监督的，客观的指标

* 噪声：度量了当前任务上任何学习算法所能达到的期望泛化误差下界，刻画了样本的标记与真实标记的区别。

关系：偏差和反差存在冲突
1. 训练不足，偏差大，欠拟合
2. 不断训练之后，方差占主导，过拟合

## 第三章
模型的形式，学习率等

### 线性回归
1. 多元线性回归（预测）
$f(x_i) = w^T x_i + b$ 使得其接近于$y_i$
2. 对数回归
$lny = w^T + b$

为了找到合适的参数theta0和theta1
* 最小二乘法：基于均方误差最小化进行模型求解的方法
* 损失函数：实际预测结果和真实结果之间的均方和的平均值
* 梯度下降：不断地迭代，更新参数值，减小损失函数的值J(theta)
	* 主要参数：alpha，theta0，theta1
	* alpha：学习率，不能过小（导致收敛率过低）也不能太大（可能产生发散或者震荡，增大误差）

### 对数几率回归（分类）
使用到了sigmod函数作为跃迁函数sigmoid(z) = 1/(1+e^(-z))

模型的含义：输出值的值与分类结果的关系

基本概念部分

### 多分类学习

将多分类拆分为多个二分类任务求解：
1. **OVO**:一对一：任意两个类别进行两两组合（全排列），总共需要N(N-1)/2
2. **OVR**:一对多：只需要训练N个训练器，一个对其余
3. MVM：多对多：不考

## 第四章(决策树)

不出计算题

对样本的分析划分属性
具体过程：从根节点不断判定直到叶子节点

### 选择最优划分属性
1. 信息增益
ID3决策树
* 信息熵：度量样本集合纯度最常用的一种指标，值越小，纯度越高。
* 使用信息增益值最大的属性作为最优划分属性。

计算过程：先对每个属性计算其对应的信息熵，然后再根据总类别的信息熵和子属性的信息熵的权重，计算信息增益，最后比较所有信息增益。

### 剪枝

1. 预剪枝：在决策树生成的过程中，在每个结点划分之前进行估计，如果当前结点的划分不能够提升决策树的泛化性能，就停止划分并标记为叶子节点。

2. 后剪枝：在决策树生成完毕之后，自底向上对非叶子节点进行考察，如果将结点对应子树替换为叶子节点能够提升决策树的泛化性能，就替换。

比较：
预剪枝直接开销降低，过拟合降低，欠拟合风险增；后剪枝的测试时间降低，过拟合风险降低。

### 连续值

连续属性离散化，二分法。

由二分法计算得到一个T值，小于T值得为一类，大于的为一类。

## 第五章（神经网络）
**前三部分**

